# Projeto de Pipeline de Dados (ETL vs. ELT) - Vacinados Recife

Este repositÃ³rio Ã© um projeto de estudo para a monitoria de Banco de Dados, focado em demonstrar, construir e comparar duas abordagens de pipeline de dados: **ETL (Extract, Transform, Load)** e **ELT (Extract, Load, Transform)**.

O projeto utiliza um conjunto de dados pÃºblicos do Portal de Dados Abertos da Prefeitura do Recife sobre as **Pessoas Vacinadas contra a Covid-19**. O desafio central Ã© a integraÃ§Ã£o de mÃºltiplos arquivos (um para cada ano: 2022, 2023, 2024) em uma base de dados Ãºnica, limpa e pronta para anÃ¡lise.

## ğŸš€ Objetivos do Projeto

  * **Demonstrar um Pipeline ETL ClÃ¡ssico:** Usando **Python (Pandas)** para extrair, unificar, limpar e transformar os dados em memÃ³ria antes de carregÃ¡-los em um banco de dados.
  * **Demonstrar um Pipeline ELT Moderno:** Usando **Python** apenas para a ExtraÃ§Ã£o e Carga (EL) dos dados brutos e o **dbt (data build tool)** para realizar todas as transformaÃ§Ãµes (T) diretamente no banco de dados com SQL.
  * **Aplicar TÃ©cnicas de Limpeza de Dados:** Lidar com valores nulos, inconsistÃªncias de formato e dados redundantes.
  * **Realizar Engenharia de Atributos:** Quebrar colunas complexas em campos utilizÃ¡veis.
  * **Gerar um "ID Ãšnico":** Criar uma chave primÃ¡ria substituta (surrogate key) para a tabela final, jÃ¡ que o `_id` original nÃ£o era confiÃ¡vel.

## ğŸ› ï¸ Tecnologias Utilizadas

  * **Linguagem:** Python 3
  * **Bibliotecas Python:** Pandas, SQLAlchemy, Psycopg2-binary
  * **Banco de Dados:** PostgreSQL
  * **Ferramenta de TransformaÃ§Ã£o (ELT):** dbt (dbt-postgres)
  * **Ambiente:** Jupyter Notebook / VS Code

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dados_vacinados_2022.csv  (Arquivo de dados brutos)
â”‚   â”œâ”€â”€ dados_vacinados_2023.csv
â”‚   â””â”€â”€ dados_vacinados_2024.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ ETL.ipynb                 (Pipeline ETL completo com Pandas)
â”‚   â””â”€â”€ ELT.ipynb            (Etapa "EL" do pipeline ELT - Carga bruta)
â”œâ”€â”€ transformacao_vacinados/      (Projeto dbt para a etapa "T")
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_vacinados_unificados.sql  (Unifica as 3 fontes)
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml                    (Define as fontes 'raw')
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”‚       â””â”€â”€ vacinados_etl_final.sql       (Modelo final com toda a limpeza)
â”‚   â””â”€â”€ dbt_project.yml
â””â”€â”€ README.md                     (Este arquivo)
```

## âš™ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

Siga estes passos para replicar o ambiente do projeto.

### PrÃ©-requisitos

  * Python 3.10+
  * Um servidor PostgreSQL instalado e rodando.
  * Git (para clonar o projeto).

### 1\. Clonar o RepositÃ³rio

```bash
git clone https://github.com/[SEU_USUARIO]/[NOME_DO_PROJETO].git
cd [NOME_DO_PROJETO]
```

### 2\. Instalar DependÃªncias

```bash
pip install pandas sqlalchemy psycopg2-binary dbt-postgres
```

### 3\. Configurar o Banco de Dados (PostgreSQL)

1.  Crie um novo banco de dados no seu PostgreSQL (ex: `projeto_banco_de_dados`).
2.  **Importante:** Atualize a `DATABASE_URL` nos notebooks `ETL.ipynb` e `ELT_load.ipynb` com seu usuÃ¡rio, senha e nome do banco.
    ```python
    DATABASE_URL = 'postgresql://postgres:SUA_SENHA@localhost:5432/projeto_monitoria'
    ```

### 4\. Configurar o dbt

1.  O `dbt` precisa de um arquivo `profiles.yml` para se conectar ao seu banco. Este arquivo **nÃ£o** fica no projeto, ele fica na sua pasta de usuÃ¡rio.

2.  VÃ¡ atÃ© `C:\Users\[SEU_USUARIO]\.dbt\` e crie/edite o arquivo `profiles.yml`.

3.  Cole a configuraÃ§Ã£o abaixo, substituindo os campos `pass` e `dbname` pelos seus:

    ```yaml
    transformacao_vacinados:
      target: dev
      outputs:
        dev:
          type: postgres
          host: localhost
          user: postgres
          pass: SUA_SENHA_AQUI
          port: 5432
          dbname: projeto_monitoria
          schema: public
    ```

## â–¶ï¸ Como Executar os Pipelines

### Pipeline 1: ETL (Abordagem com Pandas)

1.  Abra e execute todas as cÃ©lulas do notebook:
    `notebooks/ETL.ipynb`
2.  Ao final, o notebook irÃ¡ carregar o DataFrame final e limpo na tabela `vacinados_etl_final` no seu PostgreSQL.

### Pipeline 2: ELT (Abordagem com dbt)

Este pipeline tem duas etapas:

**Etapa 1: Carga (EL)**

1.  Abra e execute todas as cÃ©lulas do notebook:
    `notebooks/ELT.ipynb`
2.  Isso carregarÃ¡ os 3 CSVs **brutos** em 3 tabelas separadas no PostgreSQL: `raw_vacinados_2022`, `raw_vacinados_2023` e `raw_vacinados_2024`.

**Etapa 2: TransformaÃ§Ã£o (T)**

1.  Abra seu terminal e navegue atÃ© a pasta do projeto dbt:
    ```bash
    cd transformacao_vacinados
    ```
2.  Teste sua conexÃ£o com o banco:
    ```bash
    dbt debug
    ```
3.  Execute o pipeline de transformaÃ§Ã£o. O `dbt` irÃ¡ ler os dados brutos, unificÃ¡-los, limpÃ¡-los e criar a tabela final `vacinados_etl_final`:
    ```bash
    dbt run
    ```

## ğŸ“Š AnÃ¡lise

Com a tabela `vacinados_etl_final` (criada por qualquer um dos pipelines) pronta no banco, podemos realizar as anÃ¡lises.

*Exemplo de anÃ¡lise que pode ser feita:*

```sql
SELECT 
    grupo,
    ano_origem,
    COUNT(id) AS total_doses
FROM 
    vacinados_etl_final
GROUP BY 
    grupo, ano_origem
ORDER BY 
    ano_origem, total_doses DESC;
```
